{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19ea6bc-c48a-40ca-a1b3-6b25c5cc817b",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57d953-79db-4e45-a3f8-ad2cc9b206a1",
   "metadata": {},
   "source": [
    "ans:\n",
    "\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a16da-ab04-4fc4-bc69-5121b47aea20",
   "metadata": {},
   "source": [
    "*Lead Generation for Marketing*\n",
    "\n",
    "A web scraping software can be used to generate leads for marketing. Email and Phone lists for cold outreach can be built by scraping the data from relevant websites.\n",
    "\n",
    "*Price Comparison & Competition Monitoring*\n",
    "\n",
    "Companies catering products or services need to have comprehensive data of competitor products and services which appear in the market every day.\n",
    "\n",
    "*Data Analysis*\n",
    "\n",
    "You might want to collect and analyze data related to a specific category from multiple websites. The category might be real estate, automobiles, electronic gadgets, industrial equipment, business contacts, marketing etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1423f3-e3ab-4110-a1b7-b9e0fce5d799",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee741f5-2a10-4157-8e2d-52f17ebe6eb5",
   "metadata": {},
   "source": [
    "ans:\n",
    "\n",
    "\n",
    "The most common techniques used for Web Scraping are\n",
    "\n",
    "Human copy-and-paste.\n",
    "\n",
    "Text pattern matching.\n",
    "\n",
    "HTTP programming.\n",
    "\n",
    "HTML parsing.\n",
    "\n",
    "DOM parsing.\n",
    "\n",
    "Vertical aggregation.\n",
    "\n",
    "Semantic annotation recognizing.\n",
    "\n",
    "Computer vision web-page analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd2e8e-8305-4ad4-8d12-c320b7b1b0bd",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dde61e-7445-4257-a8ce-e6400ac02158",
   "metadata": {},
   "source": [
    "ans:\n",
    "\n",
    "Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e569a-5a74-42ea-8fea-4f1754840d32",
   "metadata": {},
   "source": [
    "Beautiful Soup provides simple methods for navigating, searching, and modifying a parse tree in HTML, XML files. It transforms a complex HTML document into a tree of Python objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02c36c-9c56-4e66-84db-1bc14d4868fb",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b557ff4-2cc7-4b34-b7f2-3a03c95d7513",
   "metadata": {},
   "source": [
    "ans:\n",
    "\n",
    "\n",
    "Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape. The first line imports the Flask class and the render_template method from the flask library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09add09-2759-4bdc-a8e4-66d06c9f464f",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070969a-ff8c-4612-ba62-d37d7310c1b1",
   "metadata": {},
   "source": [
    "ans:\n",
    "\n",
    "Code pipeline and Beanstalk are two AWS services which we used in this project.\n",
    "\n",
    "AWS CodePipeline is a continuous delivery service that enables you to model, visualize, and automate the steps required to release your software.\n",
    "Valid CodePipeline action types are source , build , test , deploy , approval , and invoke . For a list of action providers, see Valid action types and providers in CodePipeline .\n",
    "\n",
    "\n",
    "lastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic Beanstalk automatically handles the deploymentâ€”from capacity provisioning, load balancing, and auto scaling to application health monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e745bb-43f9-482c-9c95-278c0221cc97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
